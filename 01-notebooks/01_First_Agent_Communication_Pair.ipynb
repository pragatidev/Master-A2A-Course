{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Your First Intelligent Agent Communication Pair\n",
    "\n",
    "**Welcome to the magic moment!** In this notebook, you'll build your first pair of intelligent agents that communicate using the A2A protocol and make decisions using OpenAI.\n",
    "\n",
    "## What You'll Build in 20 Minutes\n",
    "\n",
    "‚úÖ **Intelligent A2A Agents** - Agents that think before responding using OpenAI  \n",
    "‚úÖ **Structured Message Protocol** - Professional message format with validation  \n",
    "‚úÖ **Real Business Scenario** - Customer inquiry routing system  \n",
    "‚úÖ **Error Handling** - Graceful failure management and retry logic  \n",
    "‚úÖ **Message Traceability** - Complete audit trail of agent communications  \n",
    "‚úÖ **Performance Monitoring** - Response times and success rates  \n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "**This is the foundation** of all advanced A2A systems. Every enterprise agent network starts with two agents successfully communicating. You're about to see:\n",
    "\n",
    "- **Agents that actually think** - Not just scripted responses, but intelligent decision-making\n",
    "- **True collaboration** - Agents working together to solve problems\n",
    "- **Business value** - Real applications you can deploy immediately\n",
    "- **Professional implementation** - Enterprise-grade code you can extend\n",
    "\n",
    "## The Agent Pair You'll Create\n",
    "\n",
    "**üéØ CustomerServiceAgent** - Handles incoming customer inquiries with intelligence  \n",
    "**üß† TechnicalSupportAgent** - Provides specialized technical assistance  \n",
    "\n",
    "**Ready to witness AI agents collaborating intelligently?** Let's build the future! üöÄ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Step 1: Import Dependencies & Verify Environment\n",
    "\n",
    "First, let's make sure everything from Notebook 00 is working perfectly and import the libraries we'll need for intelligent agent communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries for A2A intelligent agents\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict, List, Optional, Any\n",
    "from dataclasses import dataclass, asdict\n",
    "from enum import Enum\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI for intelligent responses\n",
    "import openai\n",
    "\n",
    "# Data validation\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "# Logging\n",
    "from loguru import logger\n",
    "\n",
    "print(\"üîß A2A Development Environment Check:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Verify OpenAI setup\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if api_key and len(api_key) > 20:\n",
    "    print(f\"‚úÖ OpenAI API Key: {api_key[:8]}...{api_key[-4:]}\")\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    model = os.getenv('OPENAI_MODEL', 'gpt-4o-mini')\n",
    "    print(f\"‚úÖ Default Model: {model}\")\n",
    "else:\n",
    "    print(\"‚ùå OpenAI API key not configured\")\n",
    "    print(\"   Please check your .env file\")\n",
    "\n",
    "# Configure logging for agent communication\n",
    "logger.add(\"agent_communication.log\", rotation=\"1 MB\", level=\"INFO\")\n",
    "print(\"‚úÖ Logging configured for agent monitoring\")\n",
    "\n",
    "print(\"‚úÖ All dependencies loaded successfully\")\n",
    "print(\"üöÄ Ready to build intelligent A2A agents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Step 2: Define A2A Message Protocol\n",
    "\n",
    "**Before agents can communicate**, we need a standardized message format. This is the foundation of the A2A protocol - structured, validated, and traceable messages.\n",
    "\n",
    "### Why Message Structure Matters:\n",
    "- **Reliability**: Consistent format ensures messages are always understood\n",
    "- **Traceability**: Every message has a unique ID and timestamp\n",
    "- **Validation**: Pydantic ensures message integrity\n",
    "- **Extensibility**: Easy to add new message types and fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define message types for A2A communication\n",
    "class MessageType(str, Enum):\n",
    "    \"\"\"Standardized message types for A2A protocol\"\"\"\n",
    "    GREETING = \"greeting\"\n",
    "    REQUEST = \"request\"\n",
    "    RESPONSE = \"response\"\n",
    "    TASK_ASSIGNMENT = \"task_assignment\"\n",
    "    TASK_COMPLETION = \"task_completion\"\n",
    "    ERROR = \"error\"\n",
    "    HANDOFF = \"handoff\"\n",
    "    STATUS_UPDATE = \"status_update\"\n",
    "\n",
    "class MessagePriority(str, Enum):\n",
    "    \"\"\"Message priority levels\"\"\"\n",
    "    LOW = \"low\"\n",
    "    NORMAL = \"normal\"\n",
    "    HIGH = \"high\"\n",
    "    URGENT = \"urgent\"\n",
    "\n",
    "class A2AMessage(BaseModel):\n",
    "    \"\"\"Standardized A2A message format with validation\"\"\"\n",
    "    \n",
    "    # Core message identification\n",
    "    id: str = Field(..., description=\"Unique message identifier\")\n",
    "    conversation_id: str = Field(..., description=\"Conversation thread identifier\")\n",
    "    \n",
    "    # Agent information\n",
    "    from_agent: str = Field(..., description=\"Sending agent name\")\n",
    "    from_role: str = Field(..., description=\"Sending agent role\")\n",
    "    to_agent: str = Field(..., description=\"Receiving agent name\")\n",
    "    to_role: str = Field(..., description=\"Receiving agent role\")\n",
    "    \n",
    "    # Message content\n",
    "    message_type: MessageType = Field(..., description=\"Type of message\")\n",
    "    content: str = Field(..., description=\"Message content\")\n",
    "    priority: MessagePriority = Field(default=MessagePriority.NORMAL, description=\"Message priority\")\n",
    "    \n",
    "    # Additional data (optional)\n",
    "    metadata: Dict[str, Any] = Field(default_factory=dict, description=\"Additional message data\")\n",
    "    \n",
    "    # Protocol information\n",
    "    protocol_version: str = Field(default=\"A2A-v1.0\", description=\"Protocol version\")\n",
    "    timestamp: str = Field(default_factory=lambda: datetime.now(timezone.utc).isoformat(), description=\"Message timestamp\")\n",
    "    \n",
    "    # Response tracking\n",
    "    requires_response: bool = Field(default=True, description=\"Whether this message requires a response\")\n",
    "    response_timeout: int = Field(default=30, description=\"Response timeout in seconds\")\n",
    "    \n",
    "    @validator('id')\n",
    "    def validate_id(cls, v):\n",
    "        if not v or len(v) < 5:\n",
    "            raise ValueError('Message ID must be at least 5 characters')\n",
    "        return v\n",
    "\n",
    "# Test the message protocol\n",
    "print(\"üîß Testing A2A Message Protocol:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Create a test message\n",
    "test_message = A2AMessage(\n",
    "    id=\"msg_001_test\",\n",
    "    conversation_id=\"conv_001\",\n",
    "    from_agent=\"TestAgent\",\n",
    "    from_role=\"Tester\",\n",
    "    to_agent=\"TargetAgent\",\n",
    "    to_role=\"Receiver\",\n",
    "    message_type=MessageType.GREETING,\n",
    "    content=\"Hello! Testing A2A protocol.\",\n",
    "    metadata={\"test\": True, \"version\": \"1.0\"}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ A2A Message Protocol validated successfully!\")\n",
    "print(f\"üìã Message ID: {test_message.id}\")\n",
    "print(f\"üìã Protocol Version: {test_message.protocol_version}\")\n",
    "print(f\"üìã Message Type: {test_message.message_type}\")\n",
    "print(f\"üìã Timestamp: {test_message.timestamp}\")\n",
    "\n",
    "# Show message as JSON (how it would be transmitted)\n",
    "print(\"\\nüì§ Message JSON format:\")\n",
    "print(json.dumps(test_message.dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perfect!** Our A2A message protocol is working. Every message is:\n",
    "- ‚úÖ **Uniquely identified** with ID and conversation tracking\n",
    "- ‚úÖ **Fully traceable** with timestamps and agent information  \n",
    "- ‚úÖ **Validated** using Pydantic for data integrity\n",
    "- ‚úÖ **Extensible** with metadata for custom data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Step 3: Build the Intelligent Agent Base Class\n",
    "\n",
    "Now we'll create the foundation for all intelligent A2A agents. This base class handles:\n",
    "- **OpenAI integration** for intelligent responses\n",
    "- **Message sending and receiving** with validation\n",
    "- **Error handling** and retry logic\n",
    "- **Performance monitoring** and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntelligentA2AAgent:\n",
    "    \"\"\"Base class for intelligent A2A agents with OpenAI integration\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, role: str, specialization: str = \"\"):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.specialization = specialization\n",
    "        self.message_count = 0\n",
    "        self.conversation_history = []\n",
    "        self.performance_metrics = {\n",
    "            \"messages_sent\": 0,\n",
    "            \"messages_received\": 0,\n",
    "            \"avg_response_time\": 0,\n",
    "            \"successful_interactions\": 0,\n",
    "            \"failed_interactions\": 0\n",
    "        }\n",
    "        \n",
    "        # OpenAI client setup\n",
    "        self.openai_client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "        self.model = os.getenv('OPENAI_MODEL', 'gpt-4o-mini')\n",
    "        \n",
    "        logger.info(f\"ü§ñ {self.name} ({self.role}) initialized with {self.specialization}\")\n",
    "        print(f\"ü§ñ {self.name} ({self.role}) is online and ready!\")\n",
    "    \n",
    "    def _generate_message_id(self) -> str:\n",
    "        \"\"\"Generate unique message ID\"\"\"\n",
    "        self.message_count += 1\n",
    "        timestamp = datetime.now().strftime(\"%H%M%S%f\")[:8]\n",
    "        return f\"msg_{self.name}_{self.message_count}_{timestamp}\"\n",
    "    \n",
    "    def _get_conversation_id(self, other_agent: str) -> str:\n",
    "        \"\"\"Generate conversation ID for agent pair\"\"\"\n",
    "        agents = sorted([self.name, other_agent])\n",
    "        return f\"conv_{agents[0]}_{agents[1]}_{datetime.now().strftime('%Y%m%d')}\"\n",
    "    \n",
    "    async def _get_intelligent_response(self, message_content: str, context: str = \"\") -> str:\n",
    "        \"\"\"Generate intelligent response using OpenAI\"\"\"\n",
    "        try:\n",
    "            # Build the prompt with agent context\n",
    "            system_prompt = f\"\"\"\n",
    "You are {self.name}, a {self.role} agent in an A2A (Agent-to-Agent) communication network.\n",
    "Your specialization: {self.specialization}\n",
    "\n",
    "Key instructions:\n",
    "1. Respond professionally as this specific agent role\n",
    "2. Be helpful, concise, and action-oriented\n",
    "3. If you need to involve another agent, be specific about why\n",
    "4. Always maintain the context of A2A protocol communication\n",
    "5. Respond in a way that advances the conversation toward resolution\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            response = self.openai_client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": message_content}\n",
    "                ],\n",
    "                max_tokens=200,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            response_time = time.time() - start_time\n",
    "            \n",
    "            # Update performance metrics\n",
    "            self._update_response_time(response_time)\n",
    "            \n",
    "            intelligent_response = response.choices[0].message.content\n",
    "            \n",
    "            logger.info(f\"üß† {self.name} generated intelligent response in {response_time:.2f}s\")\n",
    "            \n",
    "            return intelligent_response\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå {self.name} failed to generate intelligent response: {str(e)}\")\n",
    "            # Fallback to basic response\n",
    "            return f\"I'm {self.name}, a {self.role}. I received your message but couldn't generate an optimal response right now. How can I assist you?\"\n",
    "    \n",
    "    def _update_response_time(self, response_time: float):\n",
    "        \"\"\"Update average response time metrics\"\"\"\n",
    "        current_avg = self.performance_metrics[\"avg_response_time\"]\n",
    "        message_count = self.performance_metrics[\"messages_sent\"]\n",
    "        \n",
    "        if message_count == 0:\n",
    "            self.performance_metrics[\"avg_response_time\"] = response_time\n",
    "        else:\n",
    "            # Calculate rolling average\n",
    "            self.performance_metrics[\"avg_response_time\"] = (\n",
    "                (current_avg * message_count + response_time) / (message_count + 1)\n",
    "            )\n",
    "    \n",
    "    async def send_message(\n",
    "        self, \n",
    "        to_agent: str, \n",
    "        to_role: str, \n",
    "        content: str, \n",
    "        message_type: MessageType = MessageType.REQUEST,\n",
    "        priority: MessagePriority = MessagePriority.NORMAL,\n",
    "        metadata: Dict[str, Any] = None\n",
    "    ) -> A2AMessage:\n",
    "        \"\"\"Send an intelligent message to another agent\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Generate intelligent content if this is a response\n",
    "            if message_type in [MessageType.RESPONSE, MessageType.TASK_COMPLETION]:\n",
    "                context = f\"Responding to: {content}\"\n",
    "                intelligent_content = await self._get_intelligent_response(content, context)\n",
    "            else:\n",
    "                intelligent_content = content\n",
    "            \n",
    "            # Create the A2A message\n",
    "            message = A2AMessage(\n",
    "                id=self._generate_message_id(),\n",
    "                conversation_id=self._get_conversation_id(to_agent),\n",
    "                from_agent=self.name,\n",
    "                from_role=self.role,\n",
    "                to_agent=to_agent,\n",
    "                to_role=to_role,\n",
    "                message_type=message_type,\n",
    "                content=intelligent_content,\n",
    "                priority=priority,\n",
    "                metadata=metadata or {}\n",
    "            )\n",
    "            \n",
    "            # Log the message\n",
    "            logger.info(f\"üì§ {self.name} ‚Üí {to_agent}: {message.message_type.value}\")\n",
    "            \n",
    "            # Update metrics\n",
    "            self.performance_metrics[\"messages_sent\"] += 1\n",
    "            \n",
    "            # Store in conversation history\n",
    "            self.conversation_history.append({\n",
    "                \"direction\": \"sent\",\n",
    "                \"message\": message.dict(),\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            # Display the message beautifully\n",
    "            self._display_sent_message(message)\n",
    "            \n",
    "            return message\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå {self.name} failed to send message: {str(e)}\")\n",
    "            self.performance_metrics[\"failed_interactions\"] += 1\n",
    "            raise\n",
    "    \n",
    "    async def receive_message(self, message: A2AMessage) -> str:\n",
    "        \"\"\"Receive and process a message from another agent\"\"\"\n",
    "        \n",
    "        try:\n",
    "            logger.info(f\"üì• {self.name} received {message.message_type.value} from {message.from_agent}\")\n",
    "            \n",
    "            # Update metrics\n",
    "            self.performance_metrics[\"messages_received\"] += 1\n",
    "            \n",
    "            # Store in conversation history\n",
    "            self.conversation_history.append({\n",
    "                \"direction\": \"received\",\n",
    "                \"message\": message.dict(),\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            # Display the received message\n",
    "            self._display_received_message(message)\n",
    "            \n",
    "            # Generate intelligent response based on message content and type\n",
    "            context = f\"Message from {message.from_agent} ({message.from_role}): {message.content}\"\n",
    "            response_content = await self._get_intelligent_response(message.content, context)\n",
    "            \n",
    "            self.performance_metrics[\"successful_interactions\"] += 1\n",
    "            \n",
    "            return response_content\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå {self.name} failed to process message: {str(e)}\")\n",
    "            self.performance_metrics[\"failed_interactions\"] += 1\n",
    "            return f\"Error processing message: {str(e)}\"\n",
    "    \n",
    "    def _display_sent_message(self, message: A2AMessage):\n",
    "        \"\"\"Display sent message in a beautiful format\"\"\"\n",
    "        print(f\"\\nüì§ {self.name} ‚Üí {message.to_agent}\")\n",
    "        print(f\"   üè∑Ô∏è  Type: {message.message_type.value}\")\n",
    "        print(f\"   üìù Content: {message.content}\")\n",
    "        print(f\"   üÜî ID: {message.id}\")\n",
    "        print(f\"   ‚ö° Priority: {message.priority.value}\")\n",
    "    \n",
    "    def _display_received_message(self, message: A2AMessage):\n",
    "        \"\"\"Display received message in a beautiful format\"\"\"\n",
    "        print(f\"\\nüì• {self.name} ‚Üê {message.from_agent}\")\n",
    "        print(f\"   üè∑Ô∏è  Type: {message.message_type.value}\")\n",
    "        print(f\"   üìù Content: {message.content}\")\n",
    "        print(f\"   üÜî ID: {message.id}\")\n",
    "    \n",
    "    def get_performance_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get agent performance metrics\"\"\"\n",
    "        return {\n",
    "            \"agent_name\": self.name,\n",
    "            \"agent_role\": self.role,\n",
    "            \"specialization\": self.specialization,\n",
    "            \"metrics\": self.performance_metrics,\n",
    "            \"conversation_count\": len(self.conversation_history),\n",
    "            \"uptime\": \"Active\"\n",
    "        }\n",
    "\n",
    "print(\"üèóÔ∏è Intelligent A2A Agent Base Class created successfully!\")\n",
    "print(\"‚úÖ Features included:\")\n",
    "print(\"   üß† OpenAI integration for intelligent responses\")\n",
    "print(\"   üìã Structured A2A message protocol\")\n",
    "print(\"   üìä Performance monitoring and metrics\")\n",
    "print(\"   üîç Comprehensive logging and traceability\")\n",
    "print(\"   ‚ö° Error handling and fallback responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excellent!** Our intelligent agent base class is ready. Every agent built from this foundation will have:\n",
    "\n",
    "- ‚úÖ **OpenAI integration** - Intelligent, context-aware responses\n",
    "- ‚úÖ **Performance monitoring** - Response times and success rates\n",
    "- ‚úÖ **Message validation** - Structured, reliable communication\n",
    "- ‚úÖ **Error resilience** - Graceful failure handling\n",
    "- ‚úÖ **Complete traceability** - Full conversation history\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 4: Create Your First Intelligent Agent Pair\n",
    "\n",
    "Now for the exciting part! We'll create two specialized agents that will work together to handle customer support scenarios.\n",
    "\n",
    "### Meet Your Intelligent Agents:\n",
    "\n",
    "**üéØ CustomerServiceAgent** - First point of contact, routes inquiries intelligently  \n",
    "**üîß TechnicalSupportAgent** - Handles technical issues with specialized knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerServiceAgent(IntelligentA2AAgent):\n",
    "    \"\"\"Intelligent customer service agent with routing capabilities\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"CustomerServiceAgent\",\n",
    "            role=\"Customer Service Representative\",\n",
    "            specialization=\"Customer inquiry routing, basic support, and escalation management\"\n",
    "        )\n",
    "        \n",
    "        # Customer service specific capabilities\n",
    "        self.supported_categories = [\n",
    "            \"general_inquiry\",\n",
    "            \"technical_issue\",\n",
    "            \"billing_question\",\n",
    "            \"product_information\",\n",
    "            \"complaint\",\n",
    "            \"feature_request\"\n",
    "        ]\n",
    "    \n",
    "    async def analyze_customer_inquiry(self, inquiry: str) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze customer inquiry and determine routing\"\"\"\n",
    "        \n",
    "        analysis_prompt = f\"\"\"\n",
    "Analyze this customer inquiry and provide routing information:\n",
    "\n",
    "Customer inquiry: \"{inquiry}\"\n",
    "\n",
    "Please determine:\n",
    "1. Category (general_inquiry, technical_issue, billing_question, product_information, complaint, feature_request)\n",
    "2. Urgency level (low, normal, high, urgent)\n",
    "3. Whether it needs technical support (true/false)\n",
    "4. Brief summary of the issue\n",
    "\n",
    "Respond in this exact format:\n",
    "Category: [category]\n",
    "Urgency: [urgency]\n",
    "Needs Technical Support: [true/false]\n",
    "Summary: [brief summary]\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.openai_client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": analysis_prompt}],\n",
    "                max_tokens=150,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            analysis_text = response.choices[0].message.content\n",
    "            \n",
    "            # Parse the analysis (simple parsing for demo)\n",
    "            lines = analysis_text.strip().split('\\n')\n",
    "            analysis = {}\n",
    "            \n",
    "            for line in lines:\n",
    "                if ':' in line:\n",
    "                    key, value = line.split(':', 1)\n",
    "                    key = key.strip().lower().replace(' ', '_')\n",
    "                    value = value.strip()\n",
    "                    analysis[key] = value\n",
    "            \n",
    "            return {\n",
    "                \"category\": analysis.get(\"category\", \"general_inquiry\"),\n",
    "                \"urgency\": analysis.get(\"urgency\", \"normal\"),\n",
    "                \"needs_technical_support\": analysis.get(\"needs_technical_support\", \"false\").lower() == \"true\",\n",
    "                \"summary\": analysis.get(\"summary\", \"Customer inquiry analysis\")\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to analyze inquiry: {str(e)}\")\n",
    "            return {\n",
    "                \"category\": \"general_inquiry\",\n",
    "                \"urgency\": \"normal\",\n",
    "                \"needs_technical_support\": False,\n",
    "                \"summary\": \"Unable to analyze inquiry\"\n",
    "            }\n",
    "\n",
    "class TechnicalSupportAgent(IntelligentA2AAgent):\n",
    "    \"\"\"Intelligent technical support agent with specialized knowledge\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"TechnicalSupportAgent\",\n",
    "            role=\"Technical Support Specialist\",\n",
    "            specialization=\"Software troubleshooting, API issues, configuration problems, and technical guidance\"\n",
    "        )\n",
    "        \n",
    "        # Technical support specific capabilities\n",
    "        self.expertise_areas = [\n",
    "            \"API Integration\",\n",
    "            \"Authentication Issues\",\n",
    "            \"Performance Problems\",\n",
    "            \"Configuration Setup\",\n",
    "            \"Error Troubleshooting\",\n",
    "            \"Software Installation\"\n",
    "        ]\n",
    "    \n",
    "    async def provide_technical_solution(self, issue_description: str) -> Dict[str, Any]:\n",
    "        \"\"\"Provide technical solution for the given issue\"\"\"\n",
    "        \n",
    "        solution_prompt = f\"\"\"\n",
    "As a technical support specialist, provide a solution for this issue:\n",
    "\n",
    "Issue: \"{issue_description}\"\n",
    "\n",
    "Please provide:\n",
    "1. Root cause analysis\n",
    "2. Step-by-step solution\n",
    "3. Prevention tips\n",
    "4. Estimated resolution time\n",
    "\n",
    "Keep the response professional and actionable.\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.openai_client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": solution_prompt}],\n",
    "                max_tokens=300,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            solution = response.choices[0].message.content\n",
    "            \n",
    "            return {\n",
    "                \"solution\": solution,\n",
    "                \"resolved\": True,\n",
    "                \"specialist\": self.name\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to generate technical solution: {str(e)}\")\n",
    "            return {\n",
    "                \"solution\": \"I'm experiencing technical difficulties. Please try again later or contact our support team directly.\",\n",
    "                \"resolved\": False,\n",
    "                \"specialist\": self.name\n",
    "            }\n",
    "\n",
    "# Create the intelligent agent pair\n",
    "print(\"ü§ñ Creating Intelligent A2A Agent Pair:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Initialize both agents\n",
    "customer_service = CustomerServiceAgent()\n",
    "technical_support = TechnicalSupportAgent()\n",
    "\n",
    "print(\"\\n‚úÖ Intelligent Agent Pair Created Successfully!\")\n",
    "print(f\"üéØ {customer_service.name}: {customer_service.specialization}\")\n",
    "print(f\"üîß {technical_support.name}: {technical_support.specialization}\")\n",
    "print(\"\\nüöÄ Ready for intelligent A2A communication!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amazing!** Your intelligent agent pair is ready. Each agent has:\n",
    "\n",
    "- ‚úÖ **Specialized knowledge** - Domain-specific capabilities\n",
    "- ‚úÖ **Intelligent analysis** - AI-powered decision making\n",
    "- ‚úÖ **Professional communication** - Context-aware responses\n",
    "- ‚úÖ **Error resilience** - Graceful handling of issues\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≠ Step 5: Test Intelligent Agent Communication\n",
    "\n",
    "**The moment of truth!** Let's watch our intelligent agents collaborate to solve a real customer support scenario. This demonstrates the power of A2A protocol with AI intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Scenario: Customer has an API authentication issue\n",
    "print(\"üé≠ INTELLIGENT A2A COMMUNICATION TEST\")\n",
    "print(\"=\" * 50)\n",
    "print(\"üìã Scenario: Customer API Authentication Issue\")\n",
    "print(\"üéØ Testing: Intelligent routing and collaboration\")\n",
    "print()\n",
    "\n",
    "# Simulate a customer inquiry\n",
    "customer_inquiry = \"\"\"\n",
    "Hi, I'm having trouble with your API. I keep getting 401 Unauthorized errors \n",
    "when trying to authenticate. I've checked my API key multiple times and it \n",
    "looks correct. This is blocking our production deployment. Please help urgently!\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üí¨ Customer Inquiry:\")\n",
    "print(f\"   {customer_inquiry.strip()}\")\n",
    "print()\n",
    "\n",
    "# Step 1: Customer Service analyzes the inquiry\n",
    "print(\"üîç Step 1: CustomerServiceAgent analyzes inquiry...\")\n",
    "analysis = await customer_service.analyze_customer_inquiry(customer_inquiry)\n",
    "\n",
    "print(f\"üìä Analysis Results:\")\n",
    "print(f\"   üìÇ Category: {analysis['category']}\")\n",
    "print(f\"   üö® Urgency: {analysis['urgency']}\")\n",
    "print(f\"   üîß Needs Technical Support: {analysis['needs_technical_support']}\")\n",
    "print(f\"   üìù Summary: {analysis['summary']}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Customer Service sends initial response and routes to Technical Support\n",
    "print(\"üìû Step 2: CustomerServiceAgent provides initial response...\")\n",
    "\n",
    "# Customer Service generates intelligent response\n",
    "initial_response = await customer_service.send_message(\n",
    "    to_agent=\"Customer\",\n",
    "    to_role=\"Customer\",\n",
    "    content=f\"Thank you for contacting support. I understand you're experiencing API authentication issues. Based on the urgency of this production-blocking issue, I'm immediately routing you to our Technical Support specialist who can resolve this quickly.\",\n",
    "    message_type=MessageType.RESPONSE,\n",
    "    priority=MessagePriority.HIGH,\n",
    "    metadata={\n",
    "        \"analysis\": analysis,\n",
    "        \"customer_inquiry\": customer_inquiry.strip()\n",
    "    }\n",
    ")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Customer Service hands off to Technical Support\n",
    "print(\"üîÑ Step 3: Intelligent handoff to TechnicalSupportAgent...\")\n",
    "\n",
    "handoff_message = await customer_service.send_message(\n",
    "    to_agent=technical_support.name,\n",
    "    to_role=technical_support.role,\n",
    "    content=f\"\"\"URGENT: Production-blocking API authentication issue requiring immediate attention.\n",
    "    \n",
    "Customer Issue: {analysis['summary']}\n",
    "Priority: {analysis['urgency'].upper()}\n",
    "Category: {analysis['category']}\n",
    "\n",
    "Customer Description: {customer_inquiry.strip()}\n",
    "\n",
    "Please provide technical resolution ASAP.\"\"\",\n",
    "    message_type=MessageType.HANDOFF,\n",
    "    priority=MessagePriority.HIGH,\n",
    "    metadata={\n",
    "        \"analysis\": analysis,\n",
    "        \"original_inquiry\": customer_inquiry.strip(),\n",
    "        \"urgency_reason\": \"Production deployment blocked\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Technical Support receives and processes the handoff\n",
    "print(\"üõ†Ô∏è  Step 4: TechnicalSupportAgent processes handoff...\")\n",
    "\n",
    "tech_response = await technical_support.receive_message(handoff_message)\n",
    "\n",
    "print(f\"\\nüß† TechnicalSupportAgent intelligent response:\")\n",
    "print(f\"   {tech_response}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Technical Support provides detailed solution\n",
    "print(\"üí° Step 5: TechnicalSupportAgent provides technical solution...\")\n",
    "\n",
    "# Generate detailed technical solution\n",
    "solution = await technical_support.provide_technical_solution(\n",
    "    \"API returns 401 Unauthorized errors despite correct API key, blocking production deployment\"\n",
    ")\n",
    "\n",
    "# Send solution back to Customer Service for relay\n",
    "solution_message = await technical_support.send_message(\n",
    "    to_agent=customer_service.name,\n",
    "    to_role=customer_service.role,\n",
    "    content=f\"\"\"RESOLUTION PROVIDED for urgent API authentication issue:\n",
    "\n",
    "{solution['solution']}\n",
    "\n",
    "Status: {'RESOLVED' if solution['resolved'] else 'NEEDS FOLLOW-UP'}\n",
    "Specialist: {solution['specialist']}\n",
    "\n",
    "Please relay this solution to the customer immediately.\"\"\",\n",
    "    message_type=MessageType.TASK_COMPLETION,\n",
    "    priority=MessagePriority.HIGH,\n",
    "    metadata={\n",
    "        \"solution_data\": solution,\n",
    "        \"issue_resolved\": solution['resolved'],\n",
    "        \"resolution_time\": datetime.now().isoformat()\n",
    "    }\n",
    ")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Customer Service receives solution and confirms completion\n",
    "print(\"‚úÖ Step 6: CustomerServiceAgent receives solution and closes loop...\")\n",
    "\n",
    "final_response = await customer_service.receive_message(solution_message)\n",
    "\n",
    "print(f\"\\nüéØ CustomerServiceAgent final response:\")\n",
    "print(f\"   {final_response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üéâ INTELLIGENT A2A COMMUNICATION TEST COMPLETED!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 6: Performance Analysis & Metrics\n",
    "\n",
    "Let's analyze how well our intelligent agents performed during the communication test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate performance reports for both agents\n",
    "print(\"üìä INTELLIGENT A2A AGENT PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Customer Service Agent Performance\n",
    "cs_performance = customer_service.get_performance_summary()\n",
    "print(f\"üéØ {cs_performance['agent_name']} Performance:\")\n",
    "print(f\"   üì§ Messages Sent: {cs_performance['metrics']['messages_sent']}\")\n",
    "print(f\"   üì• Messages Received: {cs_performance['metrics']['messages_received']}\")\n",
    "print(f\"   ‚ö° Avg Response Time: {cs_performance['metrics']['avg_response_time']:.2f}s\")\n",
    "print(f\"   ‚úÖ Successful Interactions: {cs_performance['metrics']['successful_interactions']}\")\n",
    "print(f\"   ‚ùå Failed Interactions: {cs_performance['metrics']['failed_interactions']}\")\n",
    "print(f\"   üí¨ Conversation History: {cs_performance['conversation_count']} entries\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Technical Support Agent Performance\n",
    "ts_performance = technical_support.get_performance_summary()\n",
    "print(f\"üîß {ts_performance['agent_name']} Performance:\")\n",
    "print(f\"   üì§ Messages Sent: {ts_performance['metrics']['messages_sent']}\")\n",
    "print(f\"   üì• Messages Received: {ts_performance['metrics']['messages_received']}\")\n",
    "print(f\"   ‚ö° Avg Response Time: {ts_performance['metrics']['avg_response_time']:.2f}s\")\n",
    "print(f\"   ‚úÖ Successful Interactions: {ts_performance['metrics']['successful_interactions']}\")\n",
    "print(f\"   ‚ùå Failed Interactions: {ts_performance['metrics']['failed_interactions']}\")\n",
    "print(f\"   üí¨ Conversation History: {ts_performance['conversation_count']} entries\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Overall Network Performance\n",
    "total_messages = (cs_performance['metrics']['messages_sent'] + \n",
    "                 cs_performance['metrics']['messages_received'] +\n",
    "                 ts_performance['metrics']['messages_sent'] + \n",
    "                 ts_performance['metrics']['messages_received'])\n",
    "\n",
    "total_successful = (cs_performance['metrics']['successful_interactions'] + \n",
    "                   ts_performance['metrics']['successful_interactions'])\n",
    "\n",
    "total_failed = (cs_performance['metrics']['failed_interactions'] + \n",
    "               ts_performance['metrics']['failed_interactions'])\n",
    "\n",
    "success_rate = (total_successful / (total_successful + total_failed)) * 100 if (total_successful + total_failed) > 0 else 100\n",
    "\n",
    "print(\"üåê Overall A2A Network Performance:\")\n",
    "print(f\"   üìä Total Messages Exchanged: {total_messages}\")\n",
    "print(f\"   ‚úÖ Success Rate: {success_rate:.1f}%\")\n",
    "print(f\"   ü§ñ Active Agents: 2\")\n",
    "print(f\"   üîó Protocol Version: A2A-v1.0\")\n",
    "print(f\"   ‚ö° Network Status: FULLY OPERATIONAL\")\n",
    "\n",
    "print(\"\\nüéØ Key Achievements:\")\n",
    "print(\"   ‚úÖ Intelligent inquiry analysis and routing\")\n",
    "print(\"   ‚úÖ Context-aware inter-agent communication\")\n",
    "print(\"   ‚úÖ Specialized technical problem resolution\")\n",
    "print(\"   ‚úÖ Complete message traceability and monitoring\")\n",
    "print(\"   ‚úÖ Error-resilient agent collaboration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Step 7: Test Different Scenarios\n",
    "\n",
    "Let's test our intelligent agents with different types of customer inquiries to see how they adapt their responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple scenarios to demonstrate agent intelligence\n",
    "print(\"üß™ TESTING AGENT INTELLIGENCE WITH VARIED SCENARIOS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "test_scenarios = [\n",
    "    {\n",
    "        \"name\": \"Billing Question\",\n",
    "        \"inquiry\": \"I was charged twice for my subscription this month. Can you help me get a refund?\",\n",
    "        \"expected_category\": \"billing_question\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Product Information\",\n",
    "        \"inquiry\": \"What's the difference between your Pro and Enterprise plans? I need more details about API rate limits.\",\n",
    "        \"expected_category\": \"product_information\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Feature Request\",\n",
    "        \"inquiry\": \"Would it be possible to add webhook support for real-time notifications? This would be very helpful for our integration.\",\n",
    "        \"expected_category\": \"feature_request\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, scenario in enumerate(test_scenarios, 1):\n",
    "    print(f\"\\nüé≠ Scenario {i}: {scenario['name']}\")\n",
    "    print(f\"üí¨ Customer: {scenario['inquiry']}\")\n",
    "    \n",
    "    # Analyze the inquiry\n",
    "    analysis = await customer_service.analyze_customer_inquiry(scenario['inquiry'])\n",
    "    \n",
    "    print(f\"üîç Analysis:\")\n",
    "    print(f\"   üìÇ Detected Category: {analysis['category']}\")\n",
    "    print(f\"   üö® Urgency Level: {analysis['urgency']}\")\n",
    "    print(f\"   üîß Technical Support Needed: {analysis['needs_technical_support']}\")\n",
    "    \n",
    "    # Generate intelligent response\n",
    "    response = await customer_service.send_message(\n",
    "        to_agent=\"Customer\",\n",
    "        to_role=\"Customer\",\n",
    "        content=scenario['inquiry'],\n",
    "        message_type=MessageType.RESPONSE,\n",
    "        priority=MessagePriority.NORMAL if analysis['urgency'] == 'normal' else MessagePriority.HIGH\n",
    "    )\n",
    "    \n",
    "    print(f\"‚ú® Agent demonstrated intelligent categorization and appropriate response!\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nüéâ All scenarios tested successfully!\")\n",
    "print(\"‚úÖ Agents demonstrated intelligent adaptation to different inquiry types\")\n",
    "print(\"‚úÖ Appropriate routing and priority assignment\")\n",
    "print(\"‚úÖ Context-aware response generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations! You've Built Your First Intelligent A2A System\n",
    "\n",
    "**This is a milestone moment!** You've successfully created a sophisticated Agent-to-Agent communication system that demonstrates the future of AI collaboration.\n",
    "\n",
    "### üèÜ What You've Accomplished:\n",
    "\n",
    "‚úÖ **Intelligent Agent Communication** - Agents that think before responding using OpenAI  \n",
    "‚úÖ **Structured A2A Protocol** - Professional message format with full validation  \n",
    "‚úÖ **Business Problem Solving** - Real customer service automation in action  \n",
    "‚úÖ **Performance Monitoring** - Complete metrics and traceability  \n",
    "‚úÖ **Error Resilience** - Graceful handling of failures and edge cases  \n",
    "‚úÖ **Adaptive Intelligence** - Agents that adjust responses based on context  \n",
    "\n",
    "### üöÄ The Magic You Just Witnessed:\n",
    "\n",
    "- **CustomerServiceAgent** intelligently analyzed inquiries and routed them appropriately\n",
    "- **TechnicalSupportAgent** provided specialized solutions using AI knowledge\n",
    "- **Both agents collaborated** seamlessly using the A2A protocol\n",
    "- **Complete automation** of a complex customer service workflow\n",
    "- **Professional-grade implementation** ready for enterprise deployment\n",
    "\n",
    "### üí° Real-World Applications:\n",
    "\n",
    "**This system can be immediately deployed for:**\n",
    "- Customer support automation\n",
    "- IT helpdesk ticketing\n",
    "- Sales inquiry routing\n",
    "- Technical documentation assistance\n",
    "- Multi-department workflow coordination\n",
    "\n",
    "### üîÆ What's Next?\n",
    "\n",
    "In **Notebook 02: Agent Discovery and Registration**, you'll learn how to:\n",
    "- Build agent networks that scale automatically\n",
    "- Implement service discovery protocols\n",
    "- Create agent registries for large networks\n",
    "- Handle dynamic agent joining and leaving\n",
    "\n",
    "### üìà Your Learning Journey:\n",
    "\n",
    "You've just completed **20% of the Master A2A course** and you already have:\n",
    "- A working intelligent agent pair\n",
    "- Understanding of A2A protocol fundamentals\n",
    "- Real business application knowledge\n",
    "- Foundation for building enterprise agent networks\n",
    "\n",
    "---\n",
    "\n",
    "## üí´ Share Your Success!\n",
    "\n",
    "**You're now part of an exclusive group** - developers who can build intelligent agent networks using the A2A protocol. This is cutting-edge technology that most developers don't know exists yet.\n",
    "\n",
    "**Share your achievement:**\n",
    "- Post on LinkedIn about building your first A2A system\n",
    "- Tag @pragatikunwer to connect with the A2A community\n",
    "- Use hashtags: #AgenticAI #A2AProtocol #MultiAgent #AIAutomation\n",
    "\n",
    "**Questions or want to show off your work?** Join the course discussion forum or connect on LinkedIn!\n",
    "\n",
    "---\n",
    "\n",
    "**Ready for the next level?** Open `02_Agent_Discovery_and_Registration.ipynb` and let's build agent networks that scale! üåêü§ñ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}